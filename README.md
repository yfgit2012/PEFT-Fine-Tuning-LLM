# Fine Tuning Dolly model through PEFT/LoRA

The demand for using Large Language Models (LLMs) with billions of parameters has increased significantly. This poses a challenge due to the computational resources required for efficient model training and deployment. We present a practical approach to leverage the Low-Rank Adaptation (LoRA) based Parameter-Efficient Fine-Tuning (PEFT) to enable training and deploying LLMs on lower GPU resources. 

![image](https://github.com/yfgit2012/PEFT-Fine-Tuning-LLM/assets/5380211/d4c0aa77-8390-4046-b4a0-08f811fc75fa)



