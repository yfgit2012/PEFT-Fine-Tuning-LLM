# Fine Tuning Dolly model through PEFT/LoRA

The demand for using Large Language Models (LLMs) with billions of parameters has increased significantly. This poses a challenge due to the computational resources required for efficient model training and deployment. Here we present a practical approach to leverage the Low-Rank Adaptation (LoRA) based Parameter-Efficient Fine-Tuning (PEFT) to enable training and deploying LLMs on lower GPU resources. 

We present case studies using the open source, instruction-following LLM [Dolly](https://github.com/databrickslabs/dolly) - a set of instruction-following large language models trained by [Databricks](https://databricks.com/). Dolly-v2-12b is a 12 billion parameter causal language model created by Databricks that is derived from [EleutherAIâ€™s](https://www.eleuther.ai/) [Pythia-12b](https://huggingface.co/EleutherAI/pythia-12b) and fine-tuned on a [~15K record instruction corpus](https://github.com/databrickslabs/dolly/tree/master/data) generated by Databricks employees and released under a permissive license (CC-BY-SA). We evaluation results to illustrate the quantitative comparisons between LLMs of varying sizes, ranging from 3 billion to 12 billion parameters. By systematically evaluating the tradeoff between model performance and the compute resources required for fine-tuning, we provide insights into the scalability, efficiency and cost effectiveness of fine-tuning LLMs.

### Dolly Model 

Dolly 3B 

### What is PEFT/LoRA  

what is LoRA 

### Training process 

![image](https://github.com/yfgit2012/PEFT-Fine-Tuning-LLM/assets/5380211/d4c0aa77-8390-4046-b4a0-08f811fc75fa)

### Inference process 







